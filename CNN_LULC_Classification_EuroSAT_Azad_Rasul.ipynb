{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing a Convolutional Neural Network for Image Classification with PyTorch Using EuroSAT Data\n",
        "**Content Creator: Azad Rasul**\n",
        "\n",
        "\n",
        "In this article, we will implement a Convolutional Neural Network (CNN) for image classification using the EuroSAT dataset and PyTorch. EuroSAT is a dataset based on Sentinel-2 satellite images and consists of 10 classes representing different land use and land cover types.\n",
        "\n",
        "## Importing Libraries\n",
        "\n",
        "First, let's import the necessary libraries. These include standard Python libraries for file handling, data manipulation, and visualization, as well as libraries specific to deep learning.\n"
      ],
      "metadata": {
        "id": "5HA99x7sWn4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Standard Libraries\n",
        "import os  # For operating system-related tasks, such as file and directory management\n",
        "import random  # For generating random numbers, useful for creating randomized datasets\n",
        "from tqdm.notebook import tqdm  # For displaying progress bars in Jupyter Notebooks\n",
        "\n",
        "# Data manipulation and visualization\n",
        "import matplotlib.pyplot as plt  # For creating static, animated, and interactive visualizations in Python\n",
        "from PIL import Image  # For opening, manipulating, and saving many different image file formats\n",
        "import seaborn as sns  # For making statistical graphics in Python\n",
        "import pandas as pd  # For data manipulation and analysis\n",
        "import numpy as np  # For numerical computations and handling arrays\n",
        "\n",
        "# Deep Learning libraries\n",
        "import torch  # The main PyTorch library for building and training neural networks\n",
        "import torchvision  # A PyTorch library containing popular datasets, model architectures, and image transformations\n",
        "import torchsummary  # For printing a summary of the model architecture\n",
        "from torch.utils.data import Dataset, DataLoader, Subset  # For creating custom datasets and data loaders\n",
        "from torchvision import datasets, models, transforms  # For dataset handling, model architectures, and image transformations\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score  # For evaluating model performance\n",
        "import itertools  # For creating iterators for efficient looping\n"
      ],
      "metadata": {
        "id": "irG2PN89Gt-g"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up the Environment\n",
        "\n",
        "We will set a seed for reproducibility, check if a GPU is available, and set the device accordingly.\n"
      ],
      "metadata": {
        "id": "WKc_cryEXbaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility\n",
        "# Setting a seed ensures that the results are consistent and reproducible each time the code is run.\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Check if GPU is enabled\n",
        "# PyTorch allows for the use of GPU to speed up training. Here we check if a GPU is available and set the device accordingly.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    # If a GPU is available, print the name of the GPU\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "id": "fNDxjk4FG2aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the EuroSAT Dataset\n",
        "\n",
        "We will download and unzip the EuroSAT dataset.\n"
      ],
      "metadata": {
        "id": "yH0-FQ9jXsRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the EuroSAT dataset ZIP file from the specified URL\n",
        "!wget http://madm.dfki.de/files/sentinel/EuroSAT.zip -O EuroSAT.zip\n",
        "\n",
        "# Unzip the downloaded dataset into a directory named 'EuroSAT'\n",
        "!unzip -q EuroSAT.zip -d 'EuroSAT/'\n",
        "\n",
        "# Remove the ZIP file to save space now that the contents are extracted\n",
        "!rm EuroSAT.zip"
      ],
      "metadata": {
        "id": "v30ST4CjYJzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Custom Dataset Class\n",
        "\n",
        "We'll create a custom `EuroSAT` dataset class to handle the images and their corresponding labels.\n"
      ],
      "metadata": {
        "id": "y1stWKfaYYSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EuroSAT(Dataset):\n",
        "    # Initialize the EuroSAT dataset class\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        \"\"\"\n",
        "        Initializes the EuroSAT dataset class.\n",
        "\n",
        "        Parameters:\n",
        "        - dataset: The dataset to be used (assumed to be a list or other iterable of (image, label) pairs).\n",
        "        - transform: An optional transformation function to be applied to the images.\n",
        "        \"\"\"\n",
        "        self.dataset = dataset  # Store the dataset\n",
        "        self.transform = transform  # Store the optional transformation function\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Retrieve an item from the dataset.\n",
        "\n",
        "        Parameters:\n",
        "        - index: The index of the item to retrieve.\n",
        "\n",
        "        Returns:\n",
        "        - image: The image data at the specified index.\n",
        "        - label: The label associated with the image.\n",
        "        \"\"\"\n",
        "        image, label = self.dataset[index]  # Get the image and label from the dataset at the specified index\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)  # Apply the transformation if provided\n",
        "\n",
        "        return image, label  # Return the image and label\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Get the number of items in the dataset.\n",
        "\n",
        "        Returns:\n",
        "        - The length of the dataset (number of items).\n",
        "        \"\"\"\n",
        "        return len(self.dataset)  # Return the length of the dataset\n"
      ],
      "metadata": {
        "id": "4pn3ef18Y6lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the Data\n",
        "\n",
        "We will load the data, split it into training and testing sets, and create data loaders for efficient data handling.\n"
      ],
      "metadata": {
        "id": "jPEjaVehZKAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory where the dataset images are stored\n",
        "data_dir = './EuroSAT/2750/'\n",
        "\n",
        "# Create an ImageFolder dataset instance for the specified directory\n",
        "dataset = datasets.ImageFolder(data_dir)\n",
        "\n",
        "# Extract and print the class names from the dataset\n",
        "class_names = dataset.classes\n",
        "print(f\"Class names: {class_names}\")\n",
        "\n",
        "# Print the total number of classes in the dataset\n",
        "print(f\"Total number of classes: {len(class_names)}\")\n",
        "\n",
        "# Define the proportion of the dataset to be used for training\n",
        "train_size = 0.8\n",
        "\n",
        "# Generate a list of indices for all data points in the dataset\n",
        "indices = list(range(len(dataset)))\n",
        "\n",
        "# Calculate the split index for training and testing data\n",
        "split = int(train_size * len(dataset))\n",
        "\n",
        "# Shuffle the indices to randomize the dataset split\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Split the indices into training and testing indices\n",
        "train_indices, test_indices = indices[:split], indices[split:]\n",
        "\n",
        "# Create subsets of the dataset for training and testing using the indices\n",
        "train_data = EuroSAT(Subset(dataset, train_indices), train_transform)\n",
        "test_data = EuroSAT(Subset(dataset, test_indices), test_transform)\n",
        "\n",
        "# Define the batch size and the number of workers for data loading\n",
        "batch_size = 16\n",
        "num_workers = 2\n",
        "\n",
        "# Create DataLoader instances for training and testing data\n",
        "# Shuffle training data to ensure randomness during training\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "\n",
        "# Do not shuffle testing data; it's used for evaluation\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n"
      ],
      "metadata": {
        "id": "I5HkwuQOZbY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Sample Images\n",
        "\n",
        "We'll visualize some sample images from the training set to get an idea of the data.\n"
      ],
      "metadata": {
        "id": "LQ3AdISCZc2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_sample_images(dataloader, class_names, n=3):\n",
        "    \"\"\"\n",
        "    Displays a grid of sample images from the dataloader with their corresponding class names.\n",
        "\n",
        "    Parameters:\n",
        "    - dataloader: DataLoader object that provides batches of images and labels.\n",
        "    - class_names: List of class names corresponding to the labels.\n",
        "    - n: Number of rows and columns in the grid (default is 3 for a 3x3 grid).\n",
        "    \"\"\"\n",
        "    # Get a batch of images and labels from the dataloader\n",
        "    inputs, classes = next(iter(dataloader))\n",
        "\n",
        "    # Create a figure with subplots arranged in an n x n grid\n",
        "    fig, axes = plt.subplots(n, n, figsize=(8, 8))\n",
        "\n",
        "    # Iterate over each subplot position in the grid\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            # Get the image from the batch and convert from CHW to HWC format\n",
        "            image = inputs[i * n + j].numpy().transpose((1, 2, 0))\n",
        "\n",
        "            # Reverse the normalization of the image (assuming imagenet_std and imagenet_mean are defined)\n",
        "            image = np.clip(np.array(imagenet_std) * image + np.array(imagenet_mean), 0, 1)\n",
        "\n",
        "            # Get the class name for the current image\n",
        "            title = class_names[classes[i * n + j]]\n",
        "\n",
        "            # Display the image in the current subplot\n",
        "            axes[i, j].imshow(image)\n",
        "            axes[i, j].set_title(title)  # Set the title of the subplot to the class name\n",
        "            axes[i, j].axis('off')  # Hide the axis for a cleaner look\n",
        "\n",
        "    # Show the plot with the grid of images\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to display sample images from the train_loader\n",
        "show_sample_images(train_loader, class_names)\n",
        "\n"
      ],
      "metadata": {
        "id": "7YguN6KoZhUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Model\n",
        "\n",
        "We'll use a pre-trained ResNet-50 model and modify the final fully connected layer to match the number of classes in our dataset.\n"
      ],
      "metadata": {
        "id": "tTHpWT5jbERO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained ResNet-50 model\n",
        "# The 'pretrained=True' argument loads a model that has been pre-trained on ImageNet\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Replace the final fully connected layer (classifier) of the model\n",
        "# model.fc.in_features gives the number of input features to the final layer\n",
        "# len(class_names) is the number of output classes in our specific task\n",
        "# We create a new linear layer with the same input features but with an output size equal to the number of classes\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, len(class_names))\n",
        "\n",
        "# Move the model to the specified device (CPU or GPU)\n",
        "# 'device' should be a torch device object (e.g., torch.device('cuda') or torch.device('cpu'))\n",
        "model = model.to(device)\n",
        "\n",
        "# Print a summary of the model's architecture\n",
        "# The summary function shows the model's layers, output shapes, and number of parameters\n",
        "# (3, 224, 224) indicates the input shape of the images (3 channels, 224x224 pixels)\n",
        "torchsummary.summary(model, (3, 224, 224))\n"
      ],
      "metadata": {
        "id": "pGFFPkz1bFRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Loss Function and Optimizer\n",
        "\n",
        "We'll use Cross-Entropy Loss as our loss function and Stochastic Gradient Descent (SGD) as our optimizer.\n"
      ],
      "metadata": {
        "id": "0mES4EQHbLHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function\n",
        "# CrossEntropyLoss combines LogSoftmax and NLLLoss in one single class.\n",
        "# It is useful for classification problems.\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer\n",
        "# SGD stands for Stochastic Gradient Descent. It updates the parameters\n",
        "# of the model based on the gradients computed during backpropagation.\n",
        "# Here, we use the parameters of the model and set the learning rate (lr) to 0.001.\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "jygfs56ObPL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model\n",
        "\n",
        "We will define the training loop.\n"
      ],
      "metadata": {
        "id": "5wICWHW-bTIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, criterion, optimizer, device):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Initialize running totals for loss and correct predictions\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    # Loop over data batches in the dataloader\n",
        "    for inputs, labels in tqdm(dataloader):\n",
        "        # Move inputs and labels to the specified device (e.g., GPU or CPU)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients to avoid accumulation\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: compute outputs by passing inputs to the model\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss between model outputs and actual labels\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Update model parameters based on the computed gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get the predicted class with the highest score\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # Update the running loss (scaled by the batch size)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        # Update the count of correct predictions\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    # Calculate average loss and accuracy for the epoch\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "    # Return the average loss and accuracy for the epoch\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "eBHzLzEZbbvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model\n",
        "\n",
        "We'll define the evaluation loop to test the model on the validation set."
      ],
      "metadata": {
        "id": "TNRSQHxabgSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, criterion, device):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize variables to track loss, correct predictions, and store all predictions and labels\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Disable gradient computation for evaluation\n",
        "    with torch.no_grad():\n",
        "        # Iterate over the data in the dataloader\n",
        "        for inputs, labels in tqdm(dataloader):\n",
        "            # Move inputs and labels to the specified device (CPU or GPU)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Perform forward pass to get outputs from the model\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Get the predicted class by finding the index with the highest score\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # Update the running loss and correct predictions count\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # Store predictions and labels for later use (e.g., for metrics computation)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate average loss and accuracy over the entire dataset\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "    # Return the computed metrics\n",
        "    return epoch_loss, epoch_acc, all_labels, all_preds"
      ],
      "metadata": {
        "id": "5ijx7_SkbhmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Validation Loop\n",
        "\n",
        "We will train the model and validate it after each epoch, saving the best model based on validation loss.\n"
      ],
      "metadata": {
        "id": "ZtQgXICUbnY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the best model weights to the current state of the model\n",
        "best_model_wts = model.state_dict()\n",
        "\n",
        "# Set the best loss to infinity initially so that any loss will be lower\n",
        "best_loss = float('inf')\n",
        "\n",
        "# Set the number of epochs to train the model\n",
        "num_epochs = 30\n",
        "\n",
        "# Loop over the dataset multiple times (each loop is one epoch)\n",
        "for epoch in range(num_epochs):\n",
        "    # Print the current epoch number\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    # Train the model and get the training loss and accuracy\n",
        "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "    # Print the training loss and accuracy for the current epoch\n",
        "    print(f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f}\")\n",
        "\n",
        "    # Evaluate the model on the validation set and get the loss, accuracy, all labels, and all predictions\n",
        "    val_loss, val_acc, all_labels, all_preds = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    # Print the validation loss and accuracy for the current epoch\n",
        "    print(f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # If the current validation loss is lower than the best loss seen so far\n",
        "    if val_loss < best_loss:\n",
        "        # Update the best loss to the current validation loss\n",
        "        best_loss = val_loss\n",
        "        # Save the model weights as the best model weights\n",
        "        best_model_wts = model.state_dict()\n",
        "\n",
        "# Load the best model weights into the model\n",
        "model.load_state_dict(best_model_wts)\n",
        "\n",
        "# Define the directory where the model will be saved\n",
        "model_dir = \"./drive/My Drive/Colab Notebooks/models/\"\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Define the file path for saving the best model weights\n",
        "model_file = os.path.join(model_dir, 'best_model.pth')\n",
        "\n",
        "# Save the best model weights to the file\n",
        "torch.save(model.state_dict(), model_file)\n",
        "\n",
        "# Print a message indicating that the model has been saved\n",
        "print(f'Model saved to {model_file}')\n"
      ],
      "metadata": {
        "id": "8hJ-Va6cbvPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Best Model for Evaluation\n",
        "\n",
        "We will load the best model saved during training and use it for evaluation.\n"
      ],
      "metadata": {
        "id": "NG-renkMbwpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained ResNet-50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Modify the final fully connected layer to match the number of classes in your dataset\n",
        "# The original ResNet-50 has 1000 output features for 1000 classes (ImageNet dataset)\n",
        "# We replace it with a new linear layer that has 'len(class_names)' output features (number of classes in your dataset)\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, len(class_names))\n",
        "\n",
        "# Load the trained model weights from a file\n",
        "# 'model_file' is the path to the file containing the model weights\n",
        "model.load_state_dict(torch.load(model_file))\n",
        "\n",
        "# Move the model to the appropriate device (CPU or GPU)\n",
        "# 'device' is a variable specifying whether to use CPU or GPU (e.g., device = torch.device('cuda') or device = torch.device('cpu'))\n",
        "model = model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "# This is important because it changes the behavior of some layers, like dropout and batch normalization, which should behave differently during training and evaluation\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "dVgbklpVb0k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Confusion Matrix\n",
        "\n",
        "We will calculate and plot the confusion matrix to visualize the performance of our model."
      ],
      "metadata": {
        "id": "UPStBffhb4CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    # If normalization is set to True, normalize the confusion matrix\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    # Print a message indicating whether the confusion matrix is normalized or not\n",
        "    print(\"Confusion matrix, without normalization\" if not normalize else \"Normalized confusion matrix\")\n",
        "\n",
        "    # Create a new figure with a specified size\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    # Display the confusion matrix as an image\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    # Set the title of the plot\n",
        "    plt.title(title)\n",
        "    # Add a color bar to the side of the plot\n",
        "    plt.colorbar()\n",
        "    # Set tick marks at each class index\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    # Label the x-axis ticks with the class names, rotated 90 degrees\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    # Label the y-axis ticks with the class names\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    # Format the values in the confusion matrix as float with 2 decimals if normalized, otherwise as integers\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    # Determine a threshold to change text color for better readability\n",
        "    thresh = cm.max() / 2.\n",
        "    # Iterate through each cell in the confusion matrix\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        # Place the text in the middle of each cell\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    # Adjust the layout for better fit\n",
        "    plt.tight_layout()\n",
        "    # Label the y-axis as 'True label'\n",
        "    plt.ylabel('True label')\n",
        "    # Label the x-axis as 'Predicted label'\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Calculate and plot the confusion matrix\n",
        "# `all_labels` contains the true labels and `all_preds` contains the predicted labels\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "# `class_names` contains the list of class names\n",
        "plot_confusion_matrix(cm, class_names, title='Confusion Matrix')\n",
        "\n",
        "# Calculate the overall accuracy of the model\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "# Print the overall accuracy\n",
        "print(f'Overall accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "5jCz84VIcG3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making Predictions on Sample Images\n",
        "\n",
        "Finally, we will use our trained model to make predictions on some sample images from the dataset.\n"
      ],
      "metadata": {
        "id": "PPGv7z1KccCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict_image(image, model, class_names, device):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():  # Disable gradient computation for faster inference\n",
        "        # Move the image to the specified device (CPU or GPU) and make predictions\n",
        "        outputs = model(image.to(device))\n",
        "        # Get the predicted class by finding the index with the highest score\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "    # Return the name of the predicted class\n",
        "    return class_names[preds.item()]\n",
        "\n",
        "# Predict on a single sample image\n",
        "image_path = './EuroSAT/2750/Forest/Forest_10.jpg'\n",
        "image = Image.open(image_path)  # Open the image file\n",
        "input_image = test_transform(image).unsqueeze(0).to(device)  # Apply transformations and add batch dimension\n",
        "pred_class = predict_image(input_image, model, class_names, device)  # Predict the class of the image\n",
        "\n",
        "# Display the image along with the predicted class\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(image)\n",
        "ax.set_title(f\"Predicted class: {pred_class}\")\n",
        "plt.show()\n",
        "\n",
        "# Predict on multiple sample images\n",
        "sample_image_paths = [\n",
        "    './EuroSAT/2750/Industrial/Industrial_10.jpg',\n",
        "    './EuroSAT/2750/Highway/Highway_10.jpg',\n",
        "    './EuroSAT/2750/Residential/Residential_10.jpg',\n",
        "    './EuroSAT/2750/River/River_10.jpg'\n",
        "]\n",
        "\n",
        "for image_path in sample_image_paths:\n",
        "    image = Image.open(image_path)  # Open the image file\n",
        "    input_image = test_transform(image).unsqueeze(0).to(device)  # Apply transformations and add batch dimension\n",
        "    pred_class = predict_image(input_image, model, class_names, device)  # Predict the class of the image\n",
        "\n",
        "    # Display the image along with the predicted class\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(image)\n",
        "    ax.set_title(f\"Predicted class: {pred_class}\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "LtVtKDETcbVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "In this tutorial, we successfully implemented a Convolutional Neural Network (CNN) for image classification using the EuroSAT dataset and PyTorch. We went through the steps of loading the data, preprocessing it, building the model, training and evaluating it, and making predictions on sample images. This workflow can be adapted to other image classification tasks with different datasets.\n"
      ],
      "metadata": {
        "id": "luZO84UQcvuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**References**\n",
        "\n",
        "*   Helber, P., Bischke, B., Dengel, A., & Borth, D. (2018). Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification. arXiv preprint arXiv:1709.00029. Available at: https://arxiv.org/abs/1709.00029\n",
        "*   Reid Falconer, Land Use and Land Cover Classification (Beating the Benchmark). Available at: https://github.com/reidfalconer/landcover_classification\n",
        "*   Ankur Mahesh & Isabelle Tingzon, Land Use and Land Cover Classification using PyTorch. Available at: https://colab.research.google.com/drive/1Wj0LsIuotZssoQUw0QUryWk9WbOFIzV8?usp=sharing\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JJYAwzhWtYPY"
      }
    }
  ]
}